{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oClnter-j6Lt",
        "outputId": "6007ef4b-50de-4f38-f9b9-3c5dad188b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NaZe-8iPlUAg"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/clips.zip ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ORgqJ45tla1w"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/text_video_path.csv ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD_akrtPldRi",
        "outputId": "fc98391f-1001-44c8-a35e-a2dedf0b73b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  clips.zip\n",
            "   creating: clips/\n",
            "  inflating: clips/-MHnvg7xZsI_0_20.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_100_120.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_120_140.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_140_160.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_160_180.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_180_200.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_200_220.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_20_40.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_220_227.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_40_60.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_60_80.mp4  \n",
            "  inflating: clips/-MHnvg7xZsI_80_100.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_0_20.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_100_120.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_120_140.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_140_160.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_160_180.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_180_200.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_200_220.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_20_40.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_220_240.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_240_260.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_260_280.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_280_300.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_300_311.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_40_60.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_60_80.mp4  \n",
            "  inflating: clips/1pH1F6s5EQI_80_100.mp4  \n",
            "  inflating: clips/3x-dBvZl0uA_0_20.mp4  \n",
            "  inflating: clips/3x-dBvZl0uA_20_40.mp4  \n",
            "  inflating: clips/3x-dBvZl0uA_40_60.mp4  \n",
            "  inflating: clips/3x-dBvZl0uA_60_80.mp4  \n",
            "  inflating: clips/3x-dBvZl0uA_80_100.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_0_20.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_100_120.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_120_140.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_140_160.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_160_180.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_180_200.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_200_220.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_20_40.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_220_240.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_240_260.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_260_280.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_280_300.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_300_320.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_320_340.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_340_360.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_360_380.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_380_400.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_400_420.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_40_60.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_420_440.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_440_443.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_60_80.mp4  \n",
            "  inflating: clips/4x6c3Hw9cys_80_100.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_0_20.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_100_120.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_120_140.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_140_160.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_160_180.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_180_200.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_200_220.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_20_40.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_220_231.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_40_60.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_60_80.mp4  \n",
            "  inflating: clips/6jXCgNG2JXw_80_100.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_0_20.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_100_120.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_120_140.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_140_160.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_160_180.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_180_200.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_200_202.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_20_40.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_40_60.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_60_80.mp4  \n",
            "  inflating: clips/6y_j4TqxDQc_80_100.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_0_20.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_100_120.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_120_140.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_140_160.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_160_180.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_180_200.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_200_220.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_20_40.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_220_240.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_240_260.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_260_280.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_280_300.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_40_60.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_60_80.mp4  \n",
            "  inflating: clips/7z_HXFZqXqc_80_100.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_0_20.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_100_120.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_120_140.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_140_160.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_160_163.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_20_40.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_40_60.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_60_80.mp4  \n",
            "  inflating: clips/8MyFDttUqbM_80_100.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_0_20.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_100_120.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_120_140.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_140_160.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_160_180.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_180_200.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_200_220.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_20_40.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_220_240.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_240_260.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_260_280.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_280_300.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_300_320.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_40_60.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_60_80.mp4  \n",
            "  inflating: clips/Ac5nXnahi3E_80_100.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_0_20.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_100_120.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_120_140.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_140_160.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_160_180.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_180_200.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_200_220.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_20_40.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_220_240.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_240_260.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_260_280.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_280_300.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_300_320.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_320_340.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_340_345.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_40_60.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_60_80.mp4  \n",
            "  inflating: clips/ayW5B2W9hfo_80_100.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_0_20.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_100_120.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_120_140.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_140_157.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_20_40.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_40_60.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_60_80.mp4  \n",
            "  inflating: clips/bV5wI0DB7YM_80_100.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_0_20.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_100_120.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_120_140.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_140_160.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_160_180.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_180_200.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_200_220.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_20_40.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_220_240.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_240_260.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_260_280.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_280_299.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_40_60.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_60_80.mp4  \n",
            "  inflating: clips/cbzQyp-4_DU_80_100.mp4  \n",
            "  inflating: clips/Fi47A_-wvuk_0_20.mp4  \n",
            "  inflating: clips/Fi47A_-wvuk_20_40.mp4  \n",
            "  inflating: clips/Fi47A_-wvuk_40_60.mp4  \n",
            "  inflating: clips/Fi47A_-wvuk_60_71.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_0_20.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_100_120.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_120_140.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_140_160.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_160_180.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_180_183.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_20_40.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_40_60.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_60_80.mp4  \n",
            "  inflating: clips/G5Cw5FV6tec_80_100.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_0_20.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_100_120.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_120_140.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_140_160.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_160_180.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_180_200.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_200_220.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_20_40.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_40_60.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_60_80.mp4  \n",
            "  inflating: clips/Ia83UqTNApY_80_100.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_0_20.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_100_120.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_120_140.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_140_160.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_160_169.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_20_40.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_40_60.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_60_80.mp4  \n",
            "  inflating: clips/IZnaX4x5d8c_80_100.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_0_20.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_100_120.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_120_140.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_140_160.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_160_180.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_180_200.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_200_220.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_20_40.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_220_240.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_240_260.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_260_280.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_280_300.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_300_320.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_320_340.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_340_356.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_40_60.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_60_80.mp4  \n",
            "  inflating: clips/J0eBHrTN9tA_80_100.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_0_20.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_100_120.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_120_140.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_140_160.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_160_180.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_180_200.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_200_220.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_20_40.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_220_240.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_240_260.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_260_280.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_280_300.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_300_320.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_320_340.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_340_348.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_40_60.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_60_80.mp4  \n",
            "  inflating: clips/J2KvCBawzF4_80_100.mp4  \n",
            "  inflating: clips/krfXutyqPDY_0_20.mp4  \n",
            "  inflating: clips/krfXutyqPDY_100_120.mp4  \n",
            "  inflating: clips/krfXutyqPDY_120_140.mp4  \n",
            "  inflating: clips/krfXutyqPDY_140_160.mp4  \n",
            "  inflating: clips/krfXutyqPDY_160_180.mp4  \n",
            "  inflating: clips/krfXutyqPDY_180_200.mp4  \n",
            "  inflating: clips/krfXutyqPDY_200_220.mp4  \n",
            "  inflating: clips/krfXutyqPDY_20_40.mp4  \n",
            "  inflating: clips/krfXutyqPDY_220_240.mp4  \n",
            "  inflating: clips/krfXutyqPDY_240_260.mp4  \n",
            "  inflating: clips/krfXutyqPDY_260_280.mp4  \n",
            "  inflating: clips/krfXutyqPDY_280_300.mp4  \n",
            "  inflating: clips/krfXutyqPDY_300_320.mp4  \n",
            "  inflating: clips/krfXutyqPDY_320_322.mp4  \n",
            "  inflating: clips/krfXutyqPDY_40_60.mp4  \n",
            "  inflating: clips/krfXutyqPDY_60_80.mp4  \n",
            "  inflating: clips/krfXutyqPDY_80_100.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_0_20.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_100_120.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_120_140.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_140_160.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_160_180.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_180_199.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_20_40.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_40_60.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_60_80.mp4  \n",
            "  inflating: clips/kyquNfJ-rME_80_100.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_0_20.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_100_120.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_120_140.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_140_160.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_160_176.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_20_40.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_40_60.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_60_80.mp4  \n",
            "  inflating: clips/lO9PA3JkDdk_80_100.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_0_20.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1000_1020.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_100_120.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1020_1040.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1040_1060.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1060_1080.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1080_1100.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1100_1120.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1120_1140.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1140_1160.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1160_1180.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1180_1200.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1200_1220.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_120_140.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1220_1240.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1240_1260.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1260_1280.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1280_1300.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1300_1320.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1320_1340.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1340_1360.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1360_1380.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1380_1400.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1400_1420.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_140_160.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1420_1440.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1440_1460.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1460_1480.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1480_1500.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1500_1520.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1520_1540.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1540_1560.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1560_1580.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1580_1600.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1600_1620.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_160_180.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1620_1640.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1640_1660.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1660_1680.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1680_1700.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1700_1720.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1720_1740.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1740_1760.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1760_1780.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1780_1800.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1800_1820.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_180_200.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1820_1840.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1840_1860.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1860_1880.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1880_1900.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1900_1920.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1920_1940.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1940_1960.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1960_1980.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_1980_2000.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2000_2020.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_200_220.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2020_2040.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2040_2060.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2060_2080.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2080_2100.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_20_40.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2100_2120.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2120_2140.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2140_2160.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2160_2180.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2180_2200.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2200_2220.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_220_240.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2220_2240.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2240_2260.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2260_2280.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2280_2300.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2300_2320.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2320_2340.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2340_2360.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2360_2380.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2380_2400.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2400_2420.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_240_260.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2420_2440.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2440_2460.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2460_2480.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2480_2500.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2500_2520.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2520_2540.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2540_2560.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2560_2580.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2580_2600.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2600_2620.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_260_280.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2620_2640.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2640_2660.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2660_2680.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2680_2700.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2700_2720.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2720_2740.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2740_2760.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2760_2780.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2780_2800.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2800_2820.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_280_300.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2820_2840.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2840_2860.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2860_2880.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2880_2900.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2900_2920.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2920_2940.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2940_2960.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2960_2980.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_2980_3000.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3000_3020.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_300_320.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3020_3040.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3040_3060.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3060_3080.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3080_3100.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3100_3120.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3120_3140.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3140_3160.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3160_3180.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3180_3200.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3200_3220.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_320_340.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3220_3240.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3240_3260.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3260_3280.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3280_3300.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3300_3320.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3320_3340.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3340_3360.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3360_3380.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3380_3400.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3400_3420.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_340_360.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3420_3440.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3440_3460.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3460_3480.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3480_3500.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3500_3520.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3520_3540.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3540_3560.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3560_3580.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3580_3600.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3600_3620.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_360_380.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3620_3640.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3640_3660.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3660_3680.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3680_3700.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3700_3720.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3720_3740.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3740_3760.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3760_3780.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_3780_3784.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_380_400.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_400_420.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_40_60.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_420_440.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_440_460.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_460_480.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_480_500.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_500_520.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_520_540.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_540_560.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_560_580.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_580_600.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_600_620.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_60_80.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_620_640.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_640_660.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_660_680.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_680_700.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_700_720.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_720_740.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_740_760.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_760_780.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_780_800.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_800_820.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_80_100.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_820_840.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_840_860.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_860_880.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_880_900.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_900_920.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_920_940.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_940_960.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_960_980.mp4  \n",
            "  inflating: clips/lsKU38RKQSo_980_1000.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_0_20.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_100_120.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_120_140.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_140_160.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_160_180.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_180_200.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_200_220.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_20_40.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_220_240.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_240_260.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_260_280.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_280_300.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_300_306.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_40_60.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_60_80.mp4  \n",
            "  inflating: clips/N2hDKpgzdIE_80_100.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_0_20.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_100_120.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_120_140.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_140_160.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_160_180.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_180_200.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_200_220.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_20_40.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_220_240.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_240_260.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_260_280.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_280_300.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_300_320.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_320_340.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_340_358.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_40_60.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_60_80.mp4  \n",
            "  inflating: clips/nbJ-2G2GXL0_80_100.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_0_20.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_100_120.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_120_140.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_140_160.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_160_180.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_180_200.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_200_220.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_20_40.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_220_240.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_240_260.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_260_280.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_280_300.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_300_320.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_320_338.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_40_60.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_60_80.mp4  \n",
            "  inflating: clips/NDecuKLxfpo_80_100.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_0_20.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_100_120.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_120_140.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_140_160.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_160_180.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_180_200.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_200_220.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_20_40.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_220_240.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_240_260.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_260_280.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_280_300.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_300_320.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_320_329.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_40_60.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_60_80.mp4  \n",
            "  inflating: clips/NNNKz9LcfVw_80_100.mp4  \n",
            "  inflating: clips/NPguawVjbN0_0_20.mp4  \n",
            "  inflating: clips/NPguawVjbN0_100_120.mp4  \n",
            "  inflating: clips/NPguawVjbN0_120_140.mp4  \n",
            "  inflating: clips/NPguawVjbN0_140_160.mp4  \n",
            "  inflating: clips/NPguawVjbN0_160_180.mp4  \n",
            "  inflating: clips/NPguawVjbN0_180_200.mp4  \n",
            "  inflating: clips/NPguawVjbN0_200_220.mp4  \n",
            "  inflating: clips/NPguawVjbN0_20_40.mp4  \n",
            "  inflating: clips/NPguawVjbN0_220_240.mp4  \n",
            "  inflating: clips/NPguawVjbN0_240_260.mp4  \n",
            "  inflating: clips/NPguawVjbN0_260_280.mp4  \n",
            "  inflating: clips/NPguawVjbN0_280_300.mp4  \n",
            "  inflating: clips/NPguawVjbN0_300_320.mp4  \n",
            "  inflating: clips/NPguawVjbN0_320_334.mp4  \n",
            "  inflating: clips/NPguawVjbN0_40_60.mp4  \n",
            "  inflating: clips/NPguawVjbN0_60_80.mp4  \n",
            "  inflating: clips/NPguawVjbN0_80_100.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_0_20.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_100_120.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_120_140.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_140_160.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_160_180.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_180_200.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_200_220.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_20_40.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_220_240.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_240_260.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_260_280.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_280_300.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_300_301.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_40_60.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_60_80.mp4  \n",
            "  inflating: clips/NRmAXDWJVnU_80_100.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_0_20.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_100_120.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_120_140.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_140_160.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_160_180.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_180_200.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_200_220.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_20_40.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_220_240.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_240_260.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_260_280.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_280_300.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_300_303.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_40_60.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_60_80.mp4  \n",
            "  inflating: clips/o6ez9gvxLOk_80_100.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_0_20.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_100_120.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_120_140.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_140_160.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_160_180.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_180_200.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_200_220.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_20_40.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_220_240.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_240_260.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_260_280.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_280_300.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_300_306.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_40_60.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_60_80.mp4  \n",
            "  inflating: clips/p11p1IzfGFE_80_100.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_0_20.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_100_120.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_120_140.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_140_160.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_160_180.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_180_200.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_200_220.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_20_40.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_220_240.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_240_260.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_260_280.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_280_300.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_300_320.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_320_340.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_340_355.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_40_60.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_60_80.mp4  \n",
            "  inflating: clips/piVqFcuBV2c_80_100.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_0_20.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_100_120.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_120_140.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_140_160.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_160_180.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_180_200.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_200_220.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_20_40.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_220_230.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_40_60.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_60_80.mp4  \n",
            "  inflating: clips/qpZlAADOJCA_80_100.mp4  \n",
            "  inflating: clips/rwF-X5STYks_0_20.mp4  \n",
            "  inflating: clips/rwF-X5STYks_100_120.mp4  \n",
            "  inflating: clips/rwF-X5STYks_120_122.mp4  \n",
            "  inflating: clips/rwF-X5STYks_20_40.mp4  \n",
            "  inflating: clips/rwF-X5STYks_40_60.mp4  \n",
            "  inflating: clips/rwF-X5STYks_60_80.mp4  \n",
            "  inflating: clips/rwF-X5STYks_80_100.mp4  \n",
            "  inflating: clips/sOncDHXhIec_0_20.mp4  \n",
            "  inflating: clips/sOncDHXhIec_100_120.mp4  \n",
            "  inflating: clips/sOncDHXhIec_120_140.mp4  \n",
            "  inflating: clips/sOncDHXhIec_140_160.mp4  \n",
            "  inflating: clips/sOncDHXhIec_160_180.mp4  \n",
            "  inflating: clips/sOncDHXhIec_180_200.mp4  \n",
            "  inflating: clips/sOncDHXhIec_200_220.mp4  \n",
            "  inflating: clips/sOncDHXhIec_20_40.mp4  \n",
            "  inflating: clips/sOncDHXhIec_220_240.mp4  \n",
            "  inflating: clips/sOncDHXhIec_240_260.mp4  \n",
            "  inflating: clips/sOncDHXhIec_260_280.mp4  \n",
            "  inflating: clips/sOncDHXhIec_280_300.mp4  \n",
            "  inflating: clips/sOncDHXhIec_300_320.mp4  \n",
            "  inflating: clips/sOncDHXhIec_320_340.mp4  \n",
            "  inflating: clips/sOncDHXhIec_340_360.mp4  \n",
            "  inflating: clips/sOncDHXhIec_360_380.mp4  \n",
            "  inflating: clips/sOncDHXhIec_380_400.mp4  \n",
            "  inflating: clips/sOncDHXhIec_400_420.mp4  \n",
            "  inflating: clips/sOncDHXhIec_40_60.mp4  \n",
            "  inflating: clips/sOncDHXhIec_60_80.mp4  \n",
            "  inflating: clips/sOncDHXhIec_80_100.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_0_20.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_100_120.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_120_140.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_140_160.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_160_180.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_180_200.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_200_220.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_20_40.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_220_240.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_240_260.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_260_276.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_40_60.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_60_80.mp4  \n",
            "  inflating: clips/sv69UAvVOLo_80_100.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_0_20.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_100_120.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_120_140.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_140_160.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_160_180.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_180_200.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_200_220.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_20_40.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_220_240.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_240_252.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_40_60.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_60_80.mp4  \n",
            "  inflating: clips/TS3DO0ZM65Q_80_100.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_0_20.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_100_120.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_120_140.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_140_160.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_160_180.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_180_200.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_200_220.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_20_40.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_220_240.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_240_260.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_260_280.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_280_300.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_40_60.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_60_80.mp4  \n",
            "  inflating: clips/U0OV_wO_O9E_80_100.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_0_20.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_100_120.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_120_140.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_140_160.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_160_180.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_180_200.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_200_220.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_20_40.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_220_240.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_240_260.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_260_280.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_280_300.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_300_320.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_320_340.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_340_360.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_360_380.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_380_382.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_40_60.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_60_80.mp4  \n",
            "  inflating: clips/U7Cs_gDIfdA_80_100.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_0_20.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_100_120.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_120_140.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_140_160.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_160_180.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_180_200.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_200_220.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_20_40.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_40_60.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_60_80.mp4  \n",
            "  inflating: clips/uHMG2XngNYQ_80_100.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_0_20.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_100_120.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_120_140.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_140_160.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_160_180.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_180_200.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_200_220.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_20_40.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_220_240.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_240_260.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_260_269.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_40_60.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_60_80.mp4  \n",
            "  inflating: clips/uvrQjT8Hng4_80_100.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_0_20.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_100_120.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_120_140.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_140_160.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_160_180.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_180_200.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_200_220.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_20_40.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_220_240.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_240_260.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_260_280.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_280_300.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_300_320.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_320_340.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_340_344.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_40_60.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_60_80.mp4  \n",
            "  inflating: clips/vhcoXDeUUIE_80_100.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_0_20.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_100_120.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_120_140.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_140_160.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_160_180.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_180_200.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_200_220.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_20_40.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_220_240.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_240_260.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_260_279.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_40_60.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_60_80.mp4  \n",
            "  inflating: clips/Xrgk023l4lI_80_100.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_0_20.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_100_120.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_120_140.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_140_160.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_160_180.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_180_200.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_200_220.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_20_40.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_220_240.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_240_260.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_260_280.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_280_300.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_300_320.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_320_331.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_40_60.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_60_80.mp4  \n",
            "  inflating: clips/XUIjv8lprsk_80_100.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_0_20.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_100_120.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_120_140.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_140_160.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_160_180.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_180_200.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_200_220.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_20_40.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_220_240.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_240_260.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_260_280.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_280_300.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_300_316.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_40_60.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_60_80.mp4  \n",
            "  inflating: clips/ylZSxDGJR9c_80_100.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_0_20.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_100_120.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_120_140.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_140_160.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_160_180.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_180_200.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_200_220.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_20_40.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_220_240.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_240_260.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_260_280.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_280_284.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_40_60.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_60_80.mp4  \n",
            "  inflating: clips/_T42E9RkWVQ_80_100.mp4  \n"
          ]
        }
      ],
      "source": [
        "! unzip clips.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCrCNYi2ly-f",
        "outputId": "195ead68-1bb6-4f2a-82e4-705cb672c0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.33.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.7.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers transformers accelerate opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wEc_qouFl3aA"
      },
      "outputs": [],
      "source": [
        "# Text-to-Video Generation Pipeline for Google Colab\n",
        "# Optimized for limited resources with custom dataset training\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from diffusers import UNet2DConditionModel, DDPMScheduler\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YWcEMY-Zl7se"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ========================= CONFIGURATION =========================\n",
        "class Config:\n",
        "    # Model parameters\n",
        "    TEXT_ENCODER_MODEL = \"openai/clip-vit-base-patch32\"\n",
        "    VIDEO_SIZE = (64, 64)  # Small size for Colab\n",
        "    INFERENCE_SIZE = (256, 256)\n",
        "    FRAME_COUNT = 100  # Short videos for memory efficiency\n",
        "    BATCH_SIZE = 2  # Small batch size for limited GPU memory\n",
        "    LEARNING_RATE = 1e-4\n",
        "    NUM_EPOCHS = 50\n",
        "\n",
        "    # Training parameters\n",
        "    GRADIENT_ACCUMULATION_STEPS = 4\n",
        "    MIXED_PRECISION = True\n",
        "    CHECKPOINT_EVERY = 10\n",
        "\n",
        "    # Data paths\n",
        "    CSV_PATH = \"/content/text_video_path.csv\"  # Your CSV file path\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/text_to_video_latest\"\n",
        "    MODEL_SAVE_PATH = \"/content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\"\n",
        "\n",
        "        # Audio parameters\n",
        "    AUDIO_SAMPLE_RATE = 22050\n",
        "    AUDIO_DURATION = 20.0  # seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "669fxb_YmGTI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ========================= DATASET CLASS =========================\n",
        "class TextVideoDataset(Dataset):\n",
        "    def __init__(self, csv_path, transform=None):\n",
        "        self.data = pd.read_csv(csv_path, encoding='cp1252')\n",
        "        self.transform = transform\n",
        "\n",
        "        # Video preprocessing transform\n",
        "        self.video_transform = transforms.Compose([\n",
        "            transforms.Resize(Config.VIDEO_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def load_video(self, video_path):\n",
        "        \"\"\"Load video frames and resize to target resolution\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frames = []\n",
        "\n",
        "        # Read frames\n",
        "        while len(frames) < Config.FRAME_COUNT:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Convert BGR to RGB\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = Image.fromarray(frame)\n",
        "\n",
        "            # Apply transforms\n",
        "            frame = self.video_transform(frame)\n",
        "            frames.append(frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        # Pad with last frame if video is shorter\n",
        "        while len(frames) < Config.FRAME_COUNT:\n",
        "            frames.append(frames[-1] if frames else torch.zeros(3, *Config.VIDEO_SIZE))\n",
        "\n",
        "        # Stack frames: [frames, channels, height, width]\n",
        "        return torch.stack(frames[:Config.FRAME_COUNT])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text = row['text']\n",
        "        video_path = row['video_path']\n",
        "\n",
        "        # Load video\n",
        "        try:\n",
        "            video = self.load_video(video_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading video {video_path}: {e}\")\n",
        "            # Return dummy video\n",
        "            video = torch.zeros(Config.FRAME_COUNT, 3, *Config.VIDEO_SIZE)\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'video': video\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WSzQAjX4mqe5"
      },
      "outputs": [],
      "source": [
        "class TextToVideoModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Text encoder (frozen CLIP)\n",
        "        self.tokenizer = CLIPTokenizer.from_pretrained(Config.TEXT_ENCODER_MODEL)\n",
        "        self.text_encoder = CLIPTextModel.from_pretrained(Config.TEXT_ENCODER_MODEL)\n",
        "\n",
        "        # Freeze text encoder\n",
        "        for param in self.text_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Video decoder - simplified U-Net based architecture\n",
        "        self.video_decoder = VideoDecoder()\n",
        "\n",
        "        # Noise scheduler for diffusion\n",
        "        self.noise_scheduler = DDPMScheduler(\n",
        "            num_train_timesteps=1000,\n",
        "            beta_start=0.00085,\n",
        "            beta_end=0.012,\n",
        "            beta_schedule=\"scaled_linear\"\n",
        "        )\n",
        "\n",
        "    def encode_text(self, text_list):\n",
        "        \"\"\"Encode text using CLIP\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            text_list,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=77\n",
        "        )\n",
        "\n",
        "        # Move inputs to the same device as the model\n",
        "        device = next(self.text_encoder.parameters()).device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            text_embeddings = self.text_encoder(**inputs).last_hidden_state\n",
        "\n",
        "        return text_embeddings\n",
        "\n",
        "    def forward(self, text_list, target_video=None):\n",
        "        \"\"\"Forward pass for training\"\"\"\n",
        "        # Encode text\n",
        "        text_embeddings = self.encode_text(text_list)\n",
        "\n",
        "        if target_video is not None:\n",
        "            # Training mode - add noise to target video\n",
        "            # Reshape video from [batch, frames, channels, height, width] to [batch, channels, frames, height, width]\n",
        "            target_video = target_video.permute(0, 2, 1, 3, 4)\n",
        "\n",
        "            batch_size = target_video.shape[0]\n",
        "\n",
        "            # Sample random timesteps\n",
        "            timesteps = torch.randint(\n",
        "                0, self.noise_scheduler.config.num_train_timesteps,\n",
        "                (batch_size,), device=target_video.device\n",
        "            )\n",
        "\n",
        "            # Add noise to video\n",
        "            noise = torch.randn_like(target_video)\n",
        "            noisy_video = self.noise_scheduler.add_noise(target_video, noise, timesteps)\n",
        "\n",
        "            # Predict noise\n",
        "            predicted_noise = self.video_decoder(noisy_video, timesteps, text_embeddings)\n",
        "\n",
        "            return predicted_noise, noise\n",
        "        else:\n",
        "            # Inference mode\n",
        "            return self.generate_video(text_embeddings)\n",
        "\n",
        "    def generate_video(self, text_embeddings):\n",
        "        \"\"\"Generate video from text embeddings\"\"\"\n",
        "        batch_size = text_embeddings.shape[0]\n",
        "\n",
        "        # Start with random noise - correct shape [batch, channels, frames, height, width]\n",
        "        video = torch.randn(\n",
        "            batch_size, 3, Config.FRAME_COUNT, *Config.VIDEO_SIZE,\n",
        "            device=text_embeddings.device\n",
        "        )\n",
        "\n",
        "        # Denoising loop\n",
        "        for t in tqdm(self.noise_scheduler.timesteps, desc=\"Generating video\"):\n",
        "            timestep = torch.full((batch_size,), t, device=video.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                predicted_noise = self.video_decoder(video, timestep, text_embeddings)\n",
        "\n",
        "            # Remove noise\n",
        "            video = self.noise_scheduler.step(predicted_noise, t, video).prev_sample\n",
        "\n",
        "        # Convert back to [batch, frames, channels, height, width] for output\n",
        "        video = video.permute(0, 2, 1, 3, 4)\n",
        "        return video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RTgjXp9Em2pp"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VideoDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_embedding = nn.Sequential(\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512)\n",
        "        )\n",
        "\n",
        "        # Text projection\n",
        "        self.text_projection = nn.Linear(512, 512)  # CLIP embedding size\n",
        "\n",
        "        # Initial convolution\n",
        "        self.input_conv = nn.Conv3d(3, 64, 3, padding=1)\n",
        "\n",
        "        # Encoder path\n",
        "        self.down1 = nn.Sequential(\n",
        "            ResBlock3D(64, 128),\n",
        "            nn.Conv3d(128, 128, 3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.down2 = nn.Sequential(\n",
        "            ResBlock3D(128, 256),\n",
        "            nn.Conv3d(256, 256, 3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.down3 = nn.Sequential(\n",
        "            ResBlock3D(256, 512),\n",
        "            nn.Conv3d(512, 512, 3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        # Bottleneck with text conditioning\n",
        "        self.bottleneck = ResBlock3D(512 + 512, 512)  # +512 for text conditioning\n",
        "\n",
        "        # Decoder path\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(512, 512, 3, stride=2, padding=1, output_padding=1),\n",
        "            ResBlock3D(512 + 512, 256)  # +512 for skip connection\n",
        "        )\n",
        "\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(256, 256, 3, stride=2, padding=1, output_padding=1),\n",
        "            ResBlock3D(256 + 256, 128)  # +256 for skip connection\n",
        "        )\n",
        "\n",
        "        self.up3 = nn.Sequential(\n",
        "            nn.ConvTranspose3d(128, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "            ResBlock3D(128 + 128, 64)   # +128 for skip connection\n",
        "        )\n",
        "\n",
        "        # Output layer\n",
        "        self.output_conv = nn.Conv3d(64, 3, 3, padding=1)\n",
        "\n",
        "    def forward(self, video, timestep, text_embeddings):\n",
        "        # Time embedding\n",
        "        time_emb = self.get_time_embedding(timestep)\n",
        "        time_emb = self.time_embedding(time_emb)\n",
        "\n",
        "        # Text embedding (use mean pooling)\n",
        "        text_emb = self.text_projection(text_embeddings.mean(dim=1))\n",
        "\n",
        "        # Initial convolution\n",
        "        x = self.input_conv(video)\n",
        "\n",
        "        # Encoder path with skip connections\n",
        "        skip1 = self.down1[0](x, time_emb)  # ResBlock before downsampling\n",
        "        x = self.down1[1](skip1)            # Downsampling\n",
        "\n",
        "        skip2 = self.down2[0](x, time_emb)  # ResBlock before downsampling\n",
        "        x = self.down2[1](skip2)            # Downsampling\n",
        "\n",
        "        skip3 = self.down3[0](x, time_emb)  # ResBlock before downsampling\n",
        "        x = self.down3[1](skip3)            # Downsampling\n",
        "\n",
        "        # Add text conditioning to bottleneck\n",
        "        batch_size, channels, frames, height, width = x.shape\n",
        "        text_emb_spatial = text_emb.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "        text_emb_spatial = text_emb_spatial.expand(batch_size, -1, frames, height, width)\n",
        "        x = torch.cat([x, text_emb_spatial], dim=1)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x, time_emb)\n",
        "\n",
        "        # Decoder path with skip connections\n",
        "        # Up1: 512 -> 256\n",
        "        x = self.up1[0](x)  # Upsample\n",
        "        x = self.match_spatial_dims(x, skip3)  # Match dimensions\n",
        "        x = torch.cat([x, skip3], dim=1)       # Concatenate skip\n",
        "        x = self.up1[1](x, time_emb)           # ResBlock\n",
        "\n",
        "        # Up2: 256 -> 128\n",
        "        x = self.up2[0](x)  # Upsample\n",
        "        x = self.match_spatial_dims(x, skip2)  # Match dimensions\n",
        "        x = torch.cat([x, skip2], dim=1)       # Concatenate skip\n",
        "        x = self.up2[1](x, time_emb)           # ResBlock\n",
        "\n",
        "        # Up3: 128 -> 64\n",
        "        x = self.up3[0](x)  # Upsample\n",
        "        x = self.match_spatial_dims(x, skip1)  # Match dimensions\n",
        "        x = torch.cat([x, skip1], dim=1)       # Concatenate skip\n",
        "        x = self.up3[1](x, time_emb)           # ResBlock\n",
        "\n",
        "        # Output\n",
        "        return self.output_conv(x)\n",
        "\n",
        "    def match_spatial_dims(self, x, skip_conn):\n",
        "        \"\"\"Ensure spatial dimensions match before concatenation\"\"\"\n",
        "        if x.shape[2:] != skip_conn.shape[2:]:\n",
        "            x = nn.functional.interpolate(\n",
        "                x,\n",
        "                size=skip_conn.shape[2:],\n",
        "                mode='trilinear',\n",
        "                align_corners=False\n",
        "            )\n",
        "        return x\n",
        "\n",
        "    def get_time_embedding(self, timestep):\n",
        "        \"\"\"Sinusoidal time embedding\"\"\"\n",
        "        half_dim = 64\n",
        "        embeddings = np.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=timestep.device) * -embeddings)\n",
        "        embeddings = timestep[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)\n",
        "        return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0tMibTdwm7BI"
      },
      "outputs": [],
      "source": [
        "class ResBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, 3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, 3, padding=1)\n",
        "        self.norm1 = nn.GroupNorm(min(8, out_channels), out_channels)\n",
        "        self.norm2 = nn.GroupNorm(min(8, out_channels), out_channels)\n",
        "        self.time_mlp = nn.Linear(512, out_channels)\n",
        "\n",
        "        self.skip_conv = nn.Conv3d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb):\n",
        "        h = self.conv1(x)\n",
        "        h = self.norm1(h)\n",
        "\n",
        "        # Add time embedding with proper broadcasting\n",
        "        time_emb = self.time_mlp(time_emb)\n",
        "        # Reshape time embedding to match spatial dimensions\n",
        "        batch_size, channels, frames, height, width = h.shape\n",
        "        time_emb = time_emb.view(batch_size, channels, 1, 1, 1)\n",
        "        time_emb = time_emb.expand(batch_size, channels, frames, height, width)\n",
        "        h = h + time_emb\n",
        "\n",
        "        h = nn.functional.relu(h)\n",
        "        h = self.conv2(h)\n",
        "        h = self.norm2(h)\n",
        "\n",
        "        return nn.functional.relu(h + self.skip_conv(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xlvTmX_DnVqA"
      },
      "outputs": [],
      "source": [
        "# ========================= TRAINING FUNCTION =========================\n",
        "def train_model():\n",
        "    \"\"\"Main training function\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = TextVideoDataset(Config.CSV_PATH)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=Config.BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=0,  # Set to 0 for Colab compatibility\n",
        "        pin_memory=True if device.type == 'cuda' else False\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    model = TextToVideoModel().to(device)\n",
        "\n",
        "    # Move noise scheduler to device\n",
        "    model.noise_scheduler = model.noise_scheduler\n",
        "\n",
        "    optimizer = optim.AdamW(model.video_decoder.parameters(), lr=Config.LEARNING_RATE)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Mixed precision training\n",
        "    scaler = torch.cuda.amp.GradScaler() if Config.MIXED_PRECISION and device.type == 'cuda' else None\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(Config.NUM_EPOCHS):\n",
        "        epoch_loss = 0\n",
        "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{Config.NUM_EPOCHS}\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(progress_bar):\n",
        "            text_list = batch['text']\n",
        "            video = batch['video'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            if Config.MIXED_PRECISION and device.type == 'cuda':\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    predicted_noise, target_noise = model(text_list, video)\n",
        "                    loss = criterion(predicted_noise, target_noise)\n",
        "                    loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "            else:\n",
        "                predicted_noise, target_noise = model(text_list, video)\n",
        "                loss = criterion(predicted_noise, target_noise)\n",
        "                loss = loss / Config.GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                if (batch_idx + 1) % Config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            progress_bar.set_postfix({\"Loss\": loss.item()})\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % Config.CHECKPOINT_EVERY == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "            }, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
        "\n",
        "    # Save final model\n",
        "        torch.save(model.state_dict(), Config.MODEL_SAVE_PATH)\n",
        "        print(f\"Model saved to {Config.MODEL_SAVE_PATH}\")\n",
        "\n",
        "    # Plot training loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(losses)\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig('training_loss.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cZ88CRKFlozf"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "# ========================= INFERENCE FUNCTION =========================\n",
        "def generate_video_from_text(text_prompt, model_path=None, high_res=True):\n",
        "    \"\"\"Generate video from text prompt with high resolution and audio\"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load model\n",
        "    model = TextToVideoModel().to(device)\n",
        "\n",
        "    if model_path:\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Generate video\n",
        "    with torch.no_grad():\n",
        "        # Generate base video\n",
        "        generated_video = model([text_prompt])\n",
        "\n",
        "        # Upscale to higher resolution if requested\n",
        "        if high_res:\n",
        "            generated_video = upscale_video(generated_video, Config.INFERENCE_SIZE)\n",
        "\n",
        "    # Convert to numpy and denormalize\n",
        "    video = generated_video[0].cpu().numpy()\n",
        "    video = np.transpose(video, (0, 2, 3, 1))  # [frames, height, width, channels]\n",
        "\n",
        "    # Denormalize\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    video = video * std + mean\n",
        "    video = np.clip(video, 0, 1)\n",
        "\n",
        "    return video\n",
        "\n",
        "def upscale_video(video_tensor, target_size):\n",
        "    \"\"\"Upscale video to higher resolution using interpolation\"\"\"\n",
        "    # video_tensor: [batch, frames, channels, height, width]\n",
        "    batch_size, frames, channels, height, width = video_tensor.shape\n",
        "\n",
        "    # Reshape to process all frames at once\n",
        "    video_reshaped = video_tensor.view(batch_size * frames, channels, height, width)\n",
        "\n",
        "    # Upscale using bilinear interpolation\n",
        "    upscaled = nn.functional.interpolate(\n",
        "        video_reshaped,\n",
        "        size=target_size,\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    )\n",
        "\n",
        "    # Reshape back\n",
        "    upscaled = upscaled.view(batch_size, frames, channels, target_size[0], target_size[1])\n",
        "\n",
        "    return upscaled\n",
        "\n",
        "def generate_audio_from_text(text_prompt, duration=2.0):\n",
        "    \"\"\"Generate simple audio based on text prompt\"\"\"\n",
        "    sample_rate = Config.AUDIO_SAMPLE_RATE\n",
        "    t = np.linspace(0, duration, int(sample_rate * duration))\n",
        "\n",
        "    # Simple audio generation based on text characteristics\n",
        "    # This is a placeholder - you can replace with more sophisticated audio generation\n",
        "    text_hash = hash(text_prompt) % 1000\n",
        "    base_freq = 220 + (text_hash % 200)  # Vary frequency based on text\n",
        "\n",
        "    # Generate a simple melody with multiple harmonics\n",
        "    audio = np.sin(2 * np.pi * base_freq * t) * 0.3\n",
        "    audio += np.sin(2 * np.pi * base_freq * 1.5 * t) * 0.2\n",
        "    audio += np.sin(2 * np.pi * base_freq * 2 * t) * 0.1\n",
        "\n",
        "    # Add some envelope\n",
        "    envelope = np.exp(-t * 0.5)\n",
        "    audio *= envelope\n",
        "\n",
        "    # Add some variation\n",
        "    audio += np.random.normal(0, 0.05, len(audio))\n",
        "\n",
        "    return audio\n",
        "\n",
        "def save_video_as_mp4(video_frames, output_path, fps=8, audio=None):\n",
        "    \"\"\"Save video frames as MP4 with optional audio\"\"\"\n",
        "    import subprocess\n",
        "    import tempfile\n",
        "    import os\n",
        "\n",
        "    height, width = video_frames[0].shape[:2]\n",
        "\n",
        "    # Create temporary file for video without audio\n",
        "    with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video:\n",
        "        temp_video_path = temp_video.name\n",
        "\n",
        "    # Write video using OpenCV\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame in video_frames:\n",
        "        # Convert from RGB to BGR for OpenCV\n",
        "        frame_bgr = cv2.cvtColor((frame * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
        "        out.write(frame_bgr)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "    if audio is not None:\n",
        "        # Create temporary audio file\n",
        "        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:\n",
        "            temp_audio_path = temp_audio.name\n",
        "\n",
        "        # Save audio using scipy\n",
        "        try:\n",
        "            from scipy.io import wavfile\n",
        "            wavfile.write(temp_audio_path, Config.AUDIO_SAMPLE_RATE, audio.astype(np.float32))\n",
        "        except ImportError:\n",
        "            print(\"Warning: scipy not available, saving without audio\")\n",
        "            #os.rename(temp_video_path, output_path)\n",
        "            shutil.copy(temp_video_path, output_path)\n",
        "            return\n",
        "\n",
        "        # Combine video and audio using ffmpeg\n",
        "        try:\n",
        "            subprocess.run([\n",
        "                'ffmpeg', '-y',\n",
        "                '-i', temp_video_path,\n",
        "                '-i', temp_audio_path,\n",
        "                '-c:v', 'libx264',\n",
        "                '-c:a', 'aac',\n",
        "                '-strict', 'experimental',\n",
        "                '-shortest',\n",
        "                output_path\n",
        "            ], check=True, capture_output=True)\n",
        "\n",
        "            # Clean up temporary files\n",
        "            os.unlink(temp_video_path)\n",
        "            os.unlink(temp_audio_path)\n",
        "\n",
        "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
        "            print(\"Warning: ffmpeg not available, saving video without audio\")\n",
        "            #os.rename(temp_video_path, output_path)\n",
        "            shutil.copy(temp_video_path, output_path)\n",
        "    else:\n",
        "        # No audio, just rename the video file\n",
        "        #os.rename(temp_video_path, output_path)\n",
        "        shutil.copy(temp_video_path, output_path)\n",
        "\n",
        "def enhance_video_quality(video_frames):\n",
        "    \"\"\"Apply post-processing to enhance video quality\"\"\"\n",
        "    enhanced_frames = []\n",
        "\n",
        "    for frame in video_frames:\n",
        "        # Convert to uint8 for processing\n",
        "        frame_uint8 = (frame * 255).astype(np.uint8)\n",
        "\n",
        "        # Apply slight Gaussian blur to reduce noise\n",
        "        blurred = cv2.GaussianBlur(frame_uint8, (3, 3), 0.5)\n",
        "\n",
        "        # Enhance contrast\n",
        "        enhanced = cv2.convertScaleAbs(blurred, alpha=1.1, beta=10)\n",
        "\n",
        "        # Convert back to float\n",
        "        enhanced_frame = enhanced.astype(np.float32) / 255.0\n",
        "        enhanced_frames.append(enhanced_frame)\n",
        "\n",
        "    return enhanced_frames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f3hr0wwL6kJC",
        "outputId": "10a65c70-2732-4f08-ed63-ddeb62877584"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Using device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-15-4083062441.py:27: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler() if Config.MIXED_PRECISION and device.type == 'cuda' else None\n",
            "Epoch 1/50:   0%|          | 0/434 [00:00<?, ?it/s]/tmp/ipython-input-15-4083062441.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.0187]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 0.0939\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.0129]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Loss: 0.0219\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.0133]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Loss: 0.0187\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.0132]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Loss: 0.0153\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50: 100%|██████████| 434/434 [04:20<00:00,  1.66it/s, Loss=0.01]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Average Loss: 0.0129\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.0101]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Average Loss: 0.0112\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00384]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Average Loss: 0.0110\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00472]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Average Loss: 0.0087\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00476]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Average Loss: 0.0082\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00225]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Average Loss: 0.0073\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00201]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Average Loss: 0.0064\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00185]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Average Loss: 0.0060\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00559]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Average Loss: 0.0069\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00449]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Average Loss: 0.0054\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00538]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Average Loss: 0.0050\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00146]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Average Loss: 0.0047\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00239]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Average Loss: 0.0052\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00192]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Average Loss: 0.0053\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00167]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Average Loss: 0.0048\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.0011]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Average Loss: 0.0043\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00684]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Average Loss: 0.0040\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50: 100%|██████████| 434/434 [04:19<00:00,  1.67it/s, Loss=0.00149]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Average Loss: 0.0044\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00325]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23, Average Loss: 0.0047\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50: 100%|██████████| 434/434 [04:20<00:00,  1.66it/s, Loss=0.00305]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24, Average Loss: 0.0040\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00474]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25, Average Loss: 0.0039\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00783]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26, Average Loss: 0.0041\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00138]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27, Average Loss: 0.0039\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00245]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28, Average Loss: 0.0044\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00948]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29, Average Loss: 0.0044\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00284]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30, Average Loss: 0.0038\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.0153]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31, Average Loss: 0.0035\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.000851]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32, Average Loss: 0.0037\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00189]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33, Average Loss: 0.0037\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.00561]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34, Average Loss: 0.0041\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.0148]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35, Average Loss: 0.0037\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/50: 100%|██████████| 434/434 [04:20<00:00,  1.66it/s, Loss=0.00152]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36, Average Loss: 0.0036\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/50: 100%|██████████| 434/434 [04:19<00:00,  1.67it/s, Loss=0.00446]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37, Average Loss: 0.0033\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00124]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38, Average Loss: 0.0031\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00109]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39, Average Loss: 0.0033\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/50: 100%|██████████| 434/434 [04:20<00:00,  1.66it/s, Loss=0.00168]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40, Average Loss: 0.0032\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00285]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41, Average Loss: 0.0029\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00146]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42, Average Loss: 0.0030\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/50: 100%|██████████| 434/434 [04:20<00:00,  1.66it/s, Loss=0.0133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Average Loss: 0.0037\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.00146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Average Loss: 0.0036\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.000792]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Average Loss: 0.0031\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.0119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Average Loss: 0.0035\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|██████████| 434/434 [04:21<00:00,  1.66it/s, Loss=0.000678]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Average Loss: 0.0029\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|██████████| 434/434 [04:20<00:00,  1.67it/s, Loss=0.000786]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Average Loss: 0.0026\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|██████████| 434/434 [04:16<00:00,  1.69it/s, Loss=0.000868]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Average Loss: 0.0035\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|██████████| 434/434 [04:16<00:00,  1.69it/s, Loss=0.000932]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Average Loss: 0.0027\n",
            "Model saved to /content/drive/MyDrive/text_to_video_latest/text_to_video_model.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training\n",
        "print(\"Starting training...\")\n",
        "train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjFy7E6A_94X",
        "outputId": "0d0c1e34-f036-4653-f261-c79972b7099d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating sample video...\n",
            "Generating video for: you want to begin planning in detail. This is known as the project management plan.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating video: 100%|██████████| 1000/1000 [00:05<00:00, 198.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to /content/drive/MyDrive/text_to_video/generated_video_0.gif\n",
            "Generating video for: 10 to the fourth and each makes around 10 requests a day, just multiply to get five times 10 to the fifth request per\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating video: 100%|██████████| 1000/1000 [00:05<00:00, 197.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video saved to /content/drive/MyDrive/text_to_video/generated_video_1.gif\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nGenerating sample video...\")\n",
        "sample_prompts = [\n",
        "    #\"A cat playing with a ball\",\n",
        "    #\"A sunset over the ocean\",\n",
        "    #\"A person walking in the park\"\n",
        "    \"you want to begin planning in detail. This is known as the project management plan.\",\n",
        "    \"10 to the fourth and each makes around 10 requests a day, just multiply to get five times 10 to the fifth request per\"\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(sample_prompts):\n",
        "    print(f\"Generating video for: {prompt}\")\n",
        "    #video = generate_video_from_text(prompt, Config.MODEL_SAVE_PATH)\n",
        "    video = generate_video_from_text(prompt, \"/content/drive/MyDrive/text_to_video/text_to_video_model_weight.pth\")\n",
        "\n",
        "    # Save as GIF\n",
        "    output_path = os.path.join(Config.OUTPUT_DIR, f\"generated_video_{i}.gif\")\n",
        "    save_video_as_gif(video, output_path)\n",
        "    print(f\"Video saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwhuxF2zHLdi",
        "outputId": "837724a9-fe37-4838-85a2-41119ebd7fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating video for: you want to begin planning in detail. This is known as the project management plan.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating video: 100%|██████████| 1000/1000 [00:55<00:00, 18.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "High-quality video with audio saved to /content/drive/MyDrive/text_to_video_latest/generated_video_0.mp4\n",
            "Video without audio saved to /content/drive/MyDrive/text_to_video_latest/generated_video_0_no_audio.mp4\n",
            "Generating video for: 10 to the fourth and each makes around 10 requests a day, just multiply to get five times 10 to the fifth request per\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating video: 100%|██████████| 1000/1000 [00:55<00:00, 18.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "High-quality video with audio saved to /content/drive/MyDrive/text_to_video_latest/generated_video_1.mp4\n",
            "Video without audio saved to /content/drive/MyDrive/text_to_video_latest/generated_video_1_no_audio.mp4\n"
          ]
        }
      ],
      "source": [
        "sample_prompts = [\n",
        "    #\"A cat playing with a ball\",\n",
        "    #\"A sunset over the ocean\",\n",
        "    #\"A person walking in the park\"\n",
        "    \"you want to begin planning in detail. This is known as the project management plan.\",\n",
        "    \"10 to the fourth and each makes around 10 requests a day, just multiply to get five times 10 to the fifth request per\"\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(sample_prompts):\n",
        "    print(f\"Generating video for: {prompt}\")\n",
        "\n",
        "        # Generate video\n",
        "    video = generate_video_from_text(prompt, Config.MODEL_SAVE_PATH, high_res=False)\n",
        "\n",
        "        # Generate audio\n",
        "    audio = generate_audio_from_text(prompt, duration=len(video) / 8)  # 8 fps\n",
        "\n",
        "        # Enhance video quality\n",
        "    enhanced_video = enhance_video_quality(video)\n",
        "\n",
        "        # Save as MP4 with audio\n",
        "    output_path = os.path.join(Config.OUTPUT_DIR, f\"generated_video_{i}.mp4\")\n",
        "    save_video_as_mp4(enhanced_video, output_path, fps=8, audio=audio)\n",
        "    print(f\"High-quality video with audio saved to {output_path}\")\n",
        "\n",
        "        # Also save a version without audio for comparison\n",
        "    output_path_no_audio = os.path.join(Config.OUTPUT_DIR, f\"generated_video_{i}_no_audio.mp4\")\n",
        "    save_video_as_mp4(enhanced_video, output_path_no_audio, fps=8)\n",
        "    print(f\"Video without audio saved to {output_path_no_audio}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}